# 第四周

## Thinking 1   奇异值分解SVD的原理是怎样的，都有哪些应用场景？

1. **原理**

   奇异值分解在某些方面与对称矩阵基于特征向量的对角化类似。奇异值分解则是谱分析理论在任意矩阵上的推广。将不对称的矩阵A通过 $AA^{T}$ 和 $A^{T}A$ 得到两个对称的矩阵，对这$2$个对称矩阵分别求特征值和特征向量，两个对称矩阵的特征值相同，$AA^{T}$对应的特征向量称为左奇异矩阵$P$， $A^{T}A$对应的特征向量称为右奇异矩阵$Q$，特征值构成对角线矩阵$\Lambda $， $ P\Lambda Q^{T} = A$ 完成奇异值分解。

2. **应用场景**

（1）隐性语义分析 (LSA) 或隐性语义索引 (LSI)；

（2）推荐系统 ；

（3）矩阵形式数据（主要是图像数据）的压缩。



## Thinking 2   funkSVD，BiasSVD，SVD++算法之间的区别是怎样的？

1. **funkSVD**

  设置k，来对矩阵近似求解
  矩阵补全以后，再预测，实际上噪音大。
  矩阵分解之后的还原，只需要关注与原来矩阵中有值的位置进行对比即可，不需要对所有元素进行对比求解

  **损失函数：**损失函数 = P和Q矩阵乘积得到的评分，与实际用户评分之差，让损失函数最小化 => 最优化问题

2. **BiasSVD**

由于用户有自己的偏好，比如有些用户打分偏高；并且商品也有自己的偏好，比如商品的质量好
因此有了biasSVD算法，考虑到用户的偏好与商品的偏好
**将与个性化无关的部分，设置为偏好(Bias)部分**，即 $ b_{ij}=μ+b_i+b_j$
其中$μ$：所有记录的整体平均数;    $b_i$：用户偏好（与商品无关);    $b_j$：商品偏好（与用户无关)

3. **SVD++**

在BiasSVD算法基础上进行了改进，**考虑用户的隐式反馈**

隐式反馈：没有具体的评分，但可能有点击，浏览等行为
对于某一个用户$i$，假设他的隐式反馈item集合为$I(i)$
用户$i$对商品$j$对应的隐式反馈修正值为$c_{ij}$$ b_{ij}=μ+b_i+b_j$
用户$i$所有的隐式反馈修正值之和为$∑_{s ∈ N ( i )}c_{sj}$



## Thinking 3   矩阵分解算法在推荐系统中有哪些应用场景，存在哪些不足？



1. **应用场景**

   （1）收集数据，构造评分矩阵

   （2）分解评分矩阵

   （3）计算内积，排序，推荐

2. **不足**

   矩阵分解只考虑了user和item两个特征，未能考虑更多特征维度，实际上一个预测问题包含的特征维度可能很多。



## thinking 4   假设一个小说网站，有N部小说，每部小说都有摘要描述。如何针对该网站制定基于内容的推荐系统，即用户看了某部小说后，推荐其他相关的小说。原理和步骤是怎样的?

1. 对每部小说进行特征抽取，形成每部小说的特征向量
2. 计算小说之间的相似度矩阵；根据TF-IDF计算它们之间的余弦相似度，得到相似度矩阵
3. 对指定的小说，基于相似度矩阵进行由大到小排序，推荐相似度最大的Top-k部小说



## Thinking 5   Word2Vec的应用场景有哪些?

**应用场景：**

1. 在社交网络中的推荐
2. 计算商品相似度
3. NLP中作为另一个模型的输入
4. 向量的快速检索
